{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Data"
      ],
      "metadata": {
        "id": "8PrqByUNlD__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip"
      ],
      "metadata": {
        "id": "ASWF4CoRlJKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip thz zip folder\n",
        "!unzip -q Positive_tensors.zip"
      ],
      "metadata": {
        "id": "kSieKPBclimw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
        "!unzip -q Negative_tensors.zip.1"
      ],
      "metadata": {
        "id": "Yblverqilvhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "WNddg_0blwbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Auxiliary Functions"
      ],
      "metadata": {
        "id": "7x7jGteYl70Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "DbdTaNGNl2U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "HANuJ1lTmKum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class"
      ],
      "metadata": {
        "id": "VzbQy5P9mPEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        directory=\"/resources/DL0321EN/labs/Week4\"\n",
        "        positive=\"Positive_tensors\"\n",
        "        negative='Negative_tensors'\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files\n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "\n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)\n",
        "\n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "\n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "GD29sBANmNUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get current directory\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "_l0wfmxumbgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(train=True)\n",
        "validation_dataset = Dataset(train=False)\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "mnUHKeMjml87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the pre-trained model resnet18"
      ],
      "metadata": {
        "id": "RTNKJt6ymrhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "EoH3a9Opmtp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the parameter cannot be trained for the pre-trained model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False"
      ],
      "metadata": {
        "id": "KaNz5e_7mvvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#512 neurons\n",
        "model.fc = nn.Linear(in_features=512, out_features=2)"
      ],
      "metadata": {
        "id": "DGZCxJQpm3SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "L-tf7xCjm_t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train the model"
      ],
      "metadata": {
        "id": "2cd_K1OtnB5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9IAXAs_pnErF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=100)\n",
        "validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100)"
      ],
      "metadata": {
        "id": "JVZTjYCinH-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
      ],
      "metadata": {
        "id": "02p1tc6DnM92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get the accuracy"
      ],
      "metadata": {
        "id": "yfhpiGUYnROO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs=1\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "#n_epochs\n",
        "\n",
        "Loss=0\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        model.train()\n",
        "        #clear gradient\n",
        "         optimizer.zero_grad()\n",
        "        #make a prediction\n",
        "        z=model(x)\n",
        "\n",
        "        # calculate loss\n",
        "        loss=criterion(z,y)\n",
        "        # calculate gradients of parameters\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        loss_list.append(loss.data)\n",
        "    correct=0\n",
        "    for x_test, y_test in validation_loader:\n",
        "        # set model to eval\n",
        "        model.eval()\n",
        "        #make a prediction\n",
        "        z=model(x_test)\n",
        "        #find max\n",
        "        _,yhat=torch.max(z.data,1)\n",
        "\n",
        "\n",
        "        #Calculate misclassified  samples in mini-batch\n",
        "        #hint +=(yhat==y_test).sum().item()\n",
        "        correct+=(yhat==y_test).sum.item()\n",
        "\n",
        "    accuracy=correct/N_test\n",
        "    accuracy_list.append(accuracy)\n"
      ],
      "metadata": {
        "id": "Gg_xISgInTvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "wZeYeqTwnWND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot it\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CdjfDEzYnXDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the misclassified samples"
      ],
      "metadata": {
        "id": "7hmd_BxKndBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified_samples = []\n",
        "misclassified_labels = []\n",
        "misclassified_preds = []\n",
        "\n",
        "# Loop through validation data\n",
        "for x_test, y_test in validation_loader:\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    z = model(x_test)\n",
        "    _, yhat = torch.max(z.data, 1)\n",
        "\n",
        "\n",
        "    misclassified_mask = (yhat != y_test)\n",
        "    misclassified_indices = misclassified_mask.nonzero(as_tuple=True)[0]\n",
        "\n",
        "\n",
        "    for idx in misclassified_indices[:4]:\n",
        "        misclassified_samples.append(x_test[idx])\n",
        "        misclassified_labels.append(y_test[idx].item())\n",
        "        misclassified_preds.append(yhat[idx].item())\n",
        "\n",
        "\n",
        "    if len(misclassified_samples) >= 4:\n",
        "        break\n",
        "\n",
        "\n",
        "for i in range(4):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"True Label: {misclassified_labels[i]}\")\n",
        "    print(f\"Predicted Label: {misclassified_preds[i]}\")"
      ],
      "metadata": {
        "id": "oFQx3XgRneA5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}